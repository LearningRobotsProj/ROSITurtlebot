# lr_ppo/config/ppo_params.yaml
ppo:
  learning_rate: 0.0003
  gamma: 0.99
  clip_epsilon: 0.2
  ppo_epochs: 10
  batch_size: 64
  entropy_coef: 0.01
  hidden_dim: 256

training:
  total_episodes: 5000
  max_steps_per_episode: 1000
  update_frequency: 2048
  save_frequency: 100
  log_frequency: 10

robot:
  max_linear_velocity: 0.22
  max_angular_velocity: 2.84
  collision_threshold: 0.15
  goal_threshold: 0.3

observation:
  num_lidar_samples: 20
  lidar_normalization_min: 0.0
  lidar_normalization_max: 3.5
  use_goal_position: true

reward:
  goal_reached: 100.0
  collision: -50.0
  distance_multiplier: 0.1
  time_penalty: -0.05
  excessive_turn_penalty: -0.01
  max_angular_for_turn_penalty: 0.5